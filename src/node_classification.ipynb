{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://docs.dgl.ai/en/0.6.x/tutorials/blitz/1_introduction.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from dgl.data import DGLDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = pd.read_csv('../data/twitch_gamers/large_twitch_edges.csv', header=0)\n",
    "edges.columns = ['source', 'target']\n",
    "features = pd.read_csv('../data/twitch_gamers/large_twitch_features.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>views</th>\n",
       "      <th>mature</th>\n",
       "      <th>life_time</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>numeric_id</th>\n",
       "      <th>dead_account</th>\n",
       "      <th>language</th>\n",
       "      <th>affiliate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7879</td>\n",
       "      <td>1</td>\n",
       "      <td>969</td>\n",
       "      <td>2016-02-16</td>\n",
       "      <td>2018-10-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>2699</td>\n",
       "      <td>2011-05-19</td>\n",
       "      <td>2018-10-08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>EN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>382502</td>\n",
       "      <td>1</td>\n",
       "      <td>3149</td>\n",
       "      <td>2010-02-27</td>\n",
       "      <td>2018-10-12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>EN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>386</td>\n",
       "      <td>0</td>\n",
       "      <td>1344</td>\n",
       "      <td>2015-01-26</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>EN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2486</td>\n",
       "      <td>0</td>\n",
       "      <td>1784</td>\n",
       "      <td>2013-11-22</td>\n",
       "      <td>2018-10-11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>EN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168109</th>\n",
       "      <td>4965</td>\n",
       "      <td>0</td>\n",
       "      <td>810</td>\n",
       "      <td>2016-07-20</td>\n",
       "      <td>2018-10-08</td>\n",
       "      <td>168109</td>\n",
       "      <td>0</td>\n",
       "      <td>EN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168110</th>\n",
       "      <td>4128</td>\n",
       "      <td>1</td>\n",
       "      <td>2080</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2018-10-12</td>\n",
       "      <td>168110</td>\n",
       "      <td>0</td>\n",
       "      <td>EN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168111</th>\n",
       "      <td>3545</td>\n",
       "      <td>0</td>\n",
       "      <td>1797</td>\n",
       "      <td>2013-11-08</td>\n",
       "      <td>2018-10-10</td>\n",
       "      <td>168111</td>\n",
       "      <td>0</td>\n",
       "      <td>EN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168112</th>\n",
       "      <td>892736</td>\n",
       "      <td>1</td>\n",
       "      <td>2135</td>\n",
       "      <td>2012-12-07</td>\n",
       "      <td>2018-10-12</td>\n",
       "      <td>168112</td>\n",
       "      <td>0</td>\n",
       "      <td>EN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168113</th>\n",
       "      <td>791</td>\n",
       "      <td>0</td>\n",
       "      <td>2005</td>\n",
       "      <td>2013-01-22</td>\n",
       "      <td>2018-07-20</td>\n",
       "      <td>168113</td>\n",
       "      <td>0</td>\n",
       "      <td>EN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168114 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         views  mature  life_time  created_at  updated_at  numeric_id  \\\n",
       "0         7879       1        969  2016-02-16  2018-10-12           0   \n",
       "1          500       0       2699  2011-05-19  2018-10-08           1   \n",
       "2       382502       1       3149  2010-02-27  2018-10-12           2   \n",
       "3          386       0       1344  2015-01-26  2018-10-01           3   \n",
       "4         2486       0       1784  2013-11-22  2018-10-11           4   \n",
       "...        ...     ...        ...         ...         ...         ...   \n",
       "168109    4965       0        810  2016-07-20  2018-10-08      168109   \n",
       "168110    4128       1       2080  2013-01-31  2018-10-12      168110   \n",
       "168111    3545       0       1797  2013-11-08  2018-10-10      168111   \n",
       "168112  892736       1       2135  2012-12-07  2018-10-12      168112   \n",
       "168113     791       0       2005  2013-01-22  2018-07-20      168113   \n",
       "\n",
       "        dead_account language  affiliate  \n",
       "0                  0       EN          1  \n",
       "1                  0       EN          0  \n",
       "2                  0       EN          1  \n",
       "3                  0       EN          0  \n",
       "4                  0       EN          0  \n",
       "...              ...      ...        ...  \n",
       "168109             0       EN          0  \n",
       "168110             0       EN          0  \n",
       "168111             0       EN          1  \n",
       "168112             0       EN          0  \n",
       "168113             0       EN          0  \n",
       "\n",
       "[168114 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['created_at'] = pd.to_datetime(features['created_at'])\n",
    "features['updated_at'] = pd.to_datetime(features['updated_at'])\n",
    "\n",
    "features['delta_days'] = (features['updated_at'] - features['created_at']).dt.total_seconds()/(60*60*24)\n",
    "\n",
    "features['language'] = pd.factorize(features['language'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=168114, num_edges=6797557,\n",
      "      ndata_schemes={'feat': Scheme(shape=(6,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int8), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}\n",
      "      edata_schemes={})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peter\\AppData\\Local\\Temp/ipykernel_12848/506360704.py:15: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:178.)\n",
      "  node_labels = torch.from_numpy(nodes_data['affiliate'].astype('category').cat.codes.to_numpy())\n"
     ]
    }
   ],
   "source": [
    "class TwitchGamersDataset(DGLDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__(name='twitch_gamers')\n",
    "\n",
    "    def process(self):\n",
    "        nodes_data = pd.read_csv('../data/twitch_gamers/large_twitch_features.csv', header=0)\n",
    "        edges_data = pd.read_csv('../data/twitch_gamers/large_twitch_edges.csv', header=0)\n",
    "\n",
    "        nodes_data['created_at'] = pd.to_datetime(nodes_data['created_at'])\n",
    "        nodes_data['updated_at'] = pd.to_datetime(nodes_data['updated_at'])\n",
    "        nodes_data['delta_days'] = (nodes_data['updated_at'] - nodes_data['created_at']).dt.total_seconds()/(60*60*24)\n",
    "        nodes_data['language'] = pd.factorize(nodes_data['language'])[0]\n",
    "\n",
    "        node_features = torch.from_numpy(nodes_data[['views', 'mature', 'life_time', 'delta_days', 'dead_account', 'language']].to_numpy()).float()\n",
    "        node_labels = torch.from_numpy(nodes_data['affiliate'].astype('category').cat.codes.copy().to_numpy())\n",
    "        edges_src = torch.from_numpy(edges_data['numeric_id_1'].to_numpy())\n",
    "        edges_dst = torch.from_numpy(edges_data['numeric_id_2'].to_numpy())\n",
    "\n",
    "        self.graph = dgl.graph((edges_src, edges_dst), num_nodes=nodes_data.shape[0])\n",
    "        self.graph.ndata['feat'] = node_features\n",
    "        self.graph.ndata['label'] = node_labels\n",
    "\n",
    "        # If your dataset is a node classification dataset, you will need to assign\n",
    "        # masks indicating whether a node belongs to training, validation, and test set.\n",
    "        n_nodes = nodes_data.shape[0]\n",
    "        n_train = int(n_nodes * 0.6)\n",
    "        n_val = int(n_nodes * 0.2)\n",
    "        train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        train_mask[:n_train] = True\n",
    "        val_mask[n_train:n_train + n_val] = True\n",
    "        test_mask[n_train + n_val:] = True\n",
    "        self.graph.ndata['train_mask'] = train_mask\n",
    "        self.graph.ndata['val_mask'] = val_mask\n",
    "        self.graph.ndata['test_mask'] = test_mask\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.graph\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "dataset = TwitchGamersDataset()\n",
    "graph = dataset[0]\n",
    "\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "\n",
    "# Create the model with given dimensions\n",
    "model = GCN(graph.ndata['feat'].shape[1], 16, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peter\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 88574.445, val acc: 0.514 (best 0.514), test acc: 0.513 (best 0.513)\n",
      "In epoch 10, loss: 19614.129, val acc: 0.486 (best 0.514), test acc: 0.487 (best 0.513)\n",
      "In epoch 20, loss: 4804.613, val acc: 0.487 (best 0.514), test acc: 0.488 (best 0.513)\n",
      "In epoch 30, loss: 3541.513, val acc: 0.514 (best 0.514), test acc: 0.513 (best 0.513)\n",
      "In epoch 40, loss: 791.626, val acc: 0.496 (best 0.514), test acc: 0.498 (best 0.513)\n",
      "In epoch 50, loss: 760.701, val acc: 0.510 (best 0.514), test acc: 0.509 (best 0.513)\n",
      "In epoch 60, loss: 115.730, val acc: 0.474 (best 0.514), test acc: 0.472 (best 0.513)\n",
      "In epoch 70, loss: 4135.557, val acc: 0.514 (best 0.514), test acc: 0.513 (best 0.513)\n",
      "In epoch 80, loss: 2678.466, val acc: 0.514 (best 0.514), test acc: 0.513 (best 0.513)\n",
      "In epoch 90, loss: 3985.451, val acc: 0.514 (best 0.514), test acc: 0.513 (best 0.513)\n"
     ]
    }
   ],
   "source": [
    "def train(g, model):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    best_val_acc = 0\n",
    "    best_test_acc = 0\n",
    "\n",
    "    features = g.ndata['feat']\n",
    "    labels = g.ndata['label']\n",
    "    train_mask = g.ndata['train_mask']\n",
    "    val_mask = g.ndata['val_mask']\n",
    "    test_mask = g.ndata['test_mask']\n",
    "    for e in range(100):\n",
    "        # Forward\n",
    "        logits = model(g, features)\n",
    "\n",
    "        # Compute prediction\n",
    "        pred = logits.argmax(1)\n",
    "\n",
    "        # Compute loss\n",
    "        # Note that you should only compute the losses of the nodes in the training set.\n",
    "        loss = F.cross_entropy(logits[train_mask], labels[train_mask].long())\n",
    "\n",
    "        # Compute accuracy on training/validation/test\n",
    "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
    "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
    "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
    "\n",
    "        # Save the best validation accuracy and the corresponding test accuracy.\n",
    "        if best_val_acc < val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if e % 10 == 0:\n",
    "            print('In epoch {}, loss: {:.3f}, val acc: {:.3f} (best {:.3f}), test acc: {:.3f} (best {:.3f})'.format(\n",
    "                e, loss, val_acc, best_val_acc, test_acc, best_test_acc))\n",
    "\n",
    "\n",
    "graph = dgl.add_self_loop(graph)\n",
    "train(graph, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dc44e188f90d3dc04deaf720bbf8de1544c596b205badf0b60435035c6657c74"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
